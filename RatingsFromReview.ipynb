{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pnaGmNnpTRib"
      },
      "outputs": [],
      "source": [
        "from transformers import TFBertModel, BertTokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Dropout, Embedding, SpatialDropout1D\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLgsZhscx-xM"
      },
      "source": [
        "Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "N-RyjtleUG5x"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(file_path):\n",
        "    df = pd.read_csv(file_path, usecols=[\"Review\", \"Label\"])\n",
        "    df.rename(columns={\"Label\": \"Rating\"}, inplace=True)\n",
        "    tokenizer = Tokenizer(num_words=20000, lower=True)\n",
        "    tokenizer.fit_on_texts(df[\"Review\"])\n",
        "    X = tokenizer.texts_to_sequences(df[\"Review\"].values)\n",
        "    X = pad_sequences(X, maxlen=200)\n",
        "    y = df[\"Rating\"].values\n",
        "    smote = SMOTE()\n",
        "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "    return X_train, X_test, y_train, y_test, tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8muqC94RyDyy"
      },
      "source": [
        "Build LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvYaIlRgUJk8"
      },
      "outputs": [],
      "source": [
        "def build_lstm_model(input_dim, output_dim, input_length):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length))\n",
        "    model.add(SpatialDropout1D(0.2))\n",
        "    model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3inIY73UyHvV"
      },
      "source": [
        "Build Bidirectional LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JF4RlsDZyHdL"
      },
      "outputs": [],
      "source": [
        "def build_bidirectional_lstm_model(input_dim, output_dim, input_length):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length))\n",
        "    model.add(SpatialDropout1D(0.2))\n",
        "    model.add(Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2)))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TcG_6cTyPdS"
      },
      "source": [
        "Build bert model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "R7dDfWEgdwIQ"
      },
      "outputs": [],
      "source": [
        "#build random forest model with GridSearchCV\n",
        "def build_random_forest_model_with_gridsearch():\n",
        "  param_grid = {\n",
        "      'n_estimators': [25,50],\n",
        "      'max_depth': [None, 10, 20],\n",
        "      'min_samples_split': [2, 5],\n",
        "      'min_samples_leaf': [1, 2, 4]\n",
        "  }\n",
        "  rf_grid = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "  return rf_grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "cd2JgPpgevbo"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "def build_linear_regression_model_with_gridsearch():\n",
        "    # Create a pipeline to include scaling\n",
        "    pipeline = make_pipeline(\n",
        "        StandardScaler(),  # Scale the features\n",
        "        LinearRegression()\n",
        "    )\n",
        "\n",
        "    param_grid = {\n",
        "        'linearregression__fit_intercept': [True, False],\n",
        "        'linearregression__positive': [True, False]\n",
        "    }\n",
        "\n",
        "    grid_search = GridSearchCV(pipeline, param_grid, cv=5)\n",
        "    return grid_search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "7TSUQ_IKfCsv"
      },
      "outputs": [],
      "source": [
        "#build xgboost model with Grid SearchCV\n",
        "def build_xgboost_model_with_gridsearch():\n",
        "  param_grid = {\n",
        "      'n_estimators': [50, 75],\n",
        "      'max_depth': [3, 5],\n",
        "      'learning_rate': [0.1, 0.01]\n",
        "  }\n",
        "  xgb_grid = GridSearchCV(XGBRegressor(random_state=42), param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "  return xgb_grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUk6-46fyT-v"
      },
      "outputs": [],
      "source": [
        "# Train and evaluate model\n",
        "def train_and_evaluate(model, X_train, y_train, X_test, y_test, batch_size=64, epochs=40):\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test))\n",
        "    predictions = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, predictions)\n",
        "    print(f\"Mean Squared Error: {mse}\")\n",
        "    return mse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xhVEeX4sfaaC"
      },
      "outputs": [],
      "source": [
        "#train and evaluate Linear Regression, RandomForest and Xgboost\n",
        "def train_and_evaluate_with_gridsearch(model, X_train, y_train, X_test, y_test):\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, predictions)\n",
        "    print(f\"Mean Squared Error: {mse}\")\n",
        "    return mse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2ah-irZS7om3"
      },
      "outputs": [],
      "source": [
        "def save_model_and_tokenizer(model, tokenizer, model_path, tokenizer_path):\n",
        "    # Check if the model is a GridSearchCV object\n",
        "    if hasattr(model, 'best_estimator_'):\n",
        "        model = model.best_estimator_  # Extract the best model if it is\n",
        "\n",
        "    # Save the model with .keras extension if it's a Keras model\n",
        "    if hasattr(model, 'save'):\n",
        "        model.save(model_path + \".keras\")  # Add .keras extension here\n",
        "    else:\n",
        "        # Handle saving non-Keras models here, e.g., using joblib for scikit-learn models\n",
        "        import joblib\n",
        "        joblib.dump(model, model_path + \".pkl\")\n",
        "\n",
        "    # Save the tokenizer\n",
        "    with open(tokenizer_path, 'wb') as file:\n",
        "        pickle.dump(tokenizer, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gf6zfZgKcW8s",
        "outputId": "f33a8de4-23ae-4eea-bad9-ce569b5a4943"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "pL2nKGdSyVo8"
      },
      "outputs": [],
      "source": [
        "#preprocess data\n",
        "file_path = \"/content/drive/MyDrive/reviews.csv\"\n",
        "X_train, X_test, y_train, y_test, tokenizer = preprocess_data(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5MrHHBUUNFw"
      },
      "outputs": [],
      "source": [
        "# LSTM Model\n",
        "lstm_model = build_lstm_model(input_dim=20000, output_dim=128, input_length=200)\n",
        "print(\"Training LSTM Model\")\n",
        "lstm_mse = train_and_evaluate(lstm_model, X_train, y_train, X_test, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YidpqaYHUNon",
        "outputId": "bec8e6a8-f6fd-41c8-f9ef-ab96c7738813"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Bidirectional LSTM Model\n",
            "Epoch 1/40\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 446ms/step - loss: 2.2702 - mean_squared_error: 2.2702 - val_loss: 1.4229 - val_mean_squared_error: 1.4229\n",
            "Epoch 2/40\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 445ms/step - loss: 1.3442 - mean_squared_error: 1.3442 - val_loss: 1.2438 - val_mean_squared_error: 1.2438\n",
            "Epoch 3/40\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 445ms/step - loss: 1.0864 - mean_squared_error: 1.0864 - val_loss: 1.2854 - val_mean_squared_error: 1.2854\n",
            "Epoch 4/40\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 447ms/step - loss: 0.9335 - mean_squared_error: 0.9335 - val_loss: 1.2258 - val_mean_squared_error: 1.2258\n",
            "Epoch 5/40\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 448ms/step - loss: 0.8231 - mean_squared_error: 0.8231 - val_loss: 1.3293 - val_mean_squared_error: 1.3293\n",
            "Epoch 6/40\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 446ms/step - loss: 0.7357 - mean_squared_error: 0.7357 - val_loss: 1.2472 - val_mean_squared_error: 1.2472\n",
            "Epoch 7/40\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 446ms/step - loss: 0.6403 - mean_squared_error: 0.6403 - val_loss: 1.2552 - val_mean_squared_error: 1.2552\n",
            "Epoch 8/40\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 446ms/step - loss: 0.5884 - mean_squared_error: 0.5884 - val_loss: 1.3142 - val_mean_squared_error: 1.3142\n",
            "Epoch 9/40\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 447ms/step - loss: 0.5492 - mean_squared_error: 0.5492 - val_loss: 1.3826 - val_mean_squared_error: 1.3826\n",
            "Epoch 10/40\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 446ms/step - loss: 0.4921 - mean_squared_error: 0.4921 - val_loss: 1.3248 - val_mean_squared_error: 1.3248\n",
            "Epoch 11/40\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 445ms/step - loss: 0.4475 - mean_squared_error: 0.4475 - val_loss: 1.3571 - val_mean_squared_error: 1.3571\n",
            "Epoch 12/40\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 447ms/step - loss: 0.4077 - mean_squared_error: 0.4077 - val_loss: 1.3938 - val_mean_squared_error: 1.3938\n",
            "Epoch 13/40\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 447ms/step - loss: 0.3772 - mean_squared_error: 0.3772 - val_loss: 1.3867 - val_mean_squared_error: 1.3867\n",
            "Epoch 14/40\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 446ms/step - loss: 0.3553 - mean_squared_error: 0.3553 - val_loss: 1.3767 - val_mean_squared_error: 1.3767\n",
            "Epoch 15/40\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 446ms/step - loss: 0.3350 - mean_squared_error: 0.3350 - val_loss: 1.4477 - val_mean_squared_error: 1.4477\n",
            "Epoch 16/40\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 448ms/step - loss: 0.3227 - mean_squared_error: 0.3227 - val_loss: 1.4378 - val_mean_squared_error: 1.4378\n",
            "Epoch 17/40\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 447ms/step - loss: 0.3027 - mean_squared_error: 0.3027 - val_loss: 1.4283 - val_mean_squared_error: 1.4283\n",
            "Epoch 18/40\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 448ms/step - loss: 0.2798 - mean_squared_error: 0.2798 - val_loss: 1.4438 - val_mean_squared_error: 1.4438\n",
            "Epoch 19/40\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 447ms/step - loss: 0.2597 - mean_squared_error: 0.2597 - val_loss: 1.4670 - val_mean_squared_error: 1.4670\n",
            "Epoch 20/40\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 449ms/step - loss: 0.2444 - mean_squared_error: 0.2444 - val_loss: 1.4610 - val_mean_squared_error: 1.4610\n",
            "Epoch 21/40\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 448ms/step - loss: 0.2327 - mean_squared_error: 0.2327 - val_loss: 1.4655 - val_mean_squared_error: 1.4655\n",
            "Epoch 22/40\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 450ms/step - loss: 0.2293 - mean_squared_error: 0.2293 - val_loss: 1.4410 - val_mean_squared_error: 1.4410\n",
            "Epoch 23/40\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 447ms/step - loss: 0.2204 - mean_squared_error: 0.2204 - val_loss: 1.4490 - val_mean_squared_error: 1.4490\n",
            "Epoch 24/40\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 445ms/step - loss: 0.2097 - mean_squared_error: 0.2097 - val_loss: 1.4281 - val_mean_squared_error: 1.4281\n",
            "Epoch 25/40\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 447ms/step - loss: 0.1974 - mean_squared_error: 0.1974 - val_loss: 1.4400 - val_mean_squared_error: 1.4400\n",
            "Epoch 26/40\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 447ms/step - loss: 0.1959 - mean_squared_error: 0.1959 - val_loss: 1.4619 - val_mean_squared_error: 1.4619\n",
            "Epoch 27/40\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 445ms/step - loss: 0.1863 - mean_squared_error: 0.1863 - val_loss: 1.4418 - val_mean_squared_error: 1.4418\n",
            "Epoch 28/40\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 446ms/step - loss: 0.1833 - mean_squared_error: 0.1833 - val_loss: 1.4452 - val_mean_squared_error: 1.4452\n",
            "Epoch 29/40\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 447ms/step - loss: 0.1697 - mean_squared_error: 0.1697 - val_loss: 1.4435 - val_mean_squared_error: 1.4435\n",
            "Epoch 30/40\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 446ms/step - loss: 0.1689 - mean_squared_error: 0.1689 - val_loss: 1.4284 - val_mean_squared_error: 1.4284\n",
            "Epoch 31/40\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 448ms/step - loss: 0.1607 - mean_squared_error: 0.1607 - val_loss: 1.4192 - val_mean_squared_error: 1.4192\n",
            "Epoch 32/40\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 447ms/step - loss: 0.1608 - mean_squared_error: 0.1608 - val_loss: 1.4329 - val_mean_squared_error: 1.4329\n",
            "Epoch 33/40\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 449ms/step - loss: 0.1575 - mean_squared_error: 0.1575 - val_loss: 1.4125 - val_mean_squared_error: 1.4125\n",
            "Epoch 34/40\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 450ms/step - loss: 0.1495 - mean_squared_error: 0.1495 - val_loss: 1.4099 - val_mean_squared_error: 1.4099\n",
            "Epoch 35/40\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 449ms/step - loss: 0.1447 - mean_squared_error: 0.1447 - val_loss: 1.4481 - val_mean_squared_error: 1.4481\n",
            "Epoch 36/40\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 448ms/step - loss: 0.1481 - mean_squared_error: 0.1481 - val_loss: 1.4172 - val_mean_squared_error: 1.4172\n",
            "Epoch 37/40\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 448ms/step - loss: 0.1395 - mean_squared_error: 0.1395 - val_loss: 1.4225 - val_mean_squared_error: 1.4225\n",
            "Epoch 38/40\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 448ms/step - loss: 0.1358 - mean_squared_error: 0.1358 - val_loss: 1.4179 - val_mean_squared_error: 1.4179\n",
            "Epoch 39/40\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 450ms/step - loss: 0.1366 - mean_squared_error: 0.1366 - val_loss: 1.4036 - val_mean_squared_error: 1.4036\n",
            "Epoch 40/40\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 452ms/step - loss: 0.1332 - mean_squared_error: 0.1332 - val_loss: 1.4025 - val_mean_squared_error: 1.4025\n",
            "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 91ms/step\n",
            "Mean Squared Error: 1.4024547355430748\n"
          ]
        }
      ],
      "source": [
        "# Bidirectional LSTM Model\n",
        "bi_lstm_model = build_bidirectional_lstm_model(input_dim=20000, output_dim=128, input_length=200)\n",
        "print(\"Training Bidirectional LSTM Model\")\n",
        "bi_lstm_mse = train_and_evaluate(bi_lstm_model, X_train, y_train, X_test, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYujFmP0ZwQD",
        "outputId": "4ec2eccb-1b39-47d0-d61f-9780c9577f66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Random Forest Model with GridSearchCV\n",
            "Mean Squared Error: 0.46708895029097236\n"
          ]
        }
      ],
      "source": [
        "#Random Forest model with GridSearchCV\n",
        "rf_grid = build_random_forest_model_with_gridsearch()\n",
        "print(\"Training Random Forest Model with GridSearchCV\")\n",
        "rf_mse = train_and_evaluate_with_gridsearch(rf_grid, X_train, y_train, X_test, y_test)\n",
        "save_model_and_tokenizer(rf_grid, tokenizer, \"best_model\", \"tokenizer.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mo7sOL9zgFvm",
        "outputId": "9c6baade-b23a-4e5a-d728-d7a68184b631"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Linear Regression Model with GridSearchCV\n",
            "Mean Squared Error: 1.8454456323675659\n"
          ]
        }
      ],
      "source": [
        "#Linear Regression model with Grid Search CV\n",
        "lr_grid = build_linear_regression_model_with_gridsearch()\n",
        "print(\"Training Linear Regression Model with GridSearchCV\")\n",
        "lr_mse = train_and_evaluate_with_gridsearch(lr_grid, X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qki_bj4qgK-K",
        "outputId": "0bf9bd30-ef13-4c26-95b0-4fa85f907ce2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Xgboost Model with GridSearchCV\n",
            "Mean Squared Error: 1.1023760374139577\n"
          ]
        }
      ],
      "source": [
        "#xgboost model with grid search cv\n",
        "xgb_grid = build_xgboost_model_with_gridsearch()\n",
        "print(\"Training Xgboost Model with GridSearchCV\")\n",
        "xgb_mse = train_and_evaluate_with_gridsearch(xgb_grid, X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOU3FsosgiYI"
      },
      "outputs": [],
      "source": [
        "mse_scores = {\n",
        "    \"LSTM\": lstm_mse,\n",
        "    \"Bidirectional LSTM\": bi_lstm_mse,\n",
        "    \"Random Forest\": rf_mse,\n",
        "    \"Linear Regression\": lr_mse,\n",
        "    \"XGBoost\": xgb_mse\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyTX_mKD8-zn"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tK1DJWXO9AFe",
        "outputId": "ad94de19-22ad-4594-9db3-d3e67bde542a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The best model is Random Forest with a mean squared error of 0.4726753968709584.\n"
          ]
        }
      ],
      "source": [
        "# Determine the best model\n",
        "best_model = min(mse_scores, key=mse_scores.get)\n",
        "print(f\"The best model is {best_model} with a mean squared error of {mse_scores[best_model]}.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhzMkDNikUAR"
      },
      "source": [
        "Save the best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NkPR0Xqg59v"
      },
      "outputs": [],
      "source": [
        "#save the best model, tokenizer based on the mse\n",
        "from google.colab import files\n",
        "if best_model == \"LSTM\":\n",
        "    save_model_and_tokenizer(lstm_model, tokenizer, \"best_model\", \"tokenizer.pkl\")\n",
        "    files.download('best_model.pkl')\n",
        "elif best_model == \"Bidirectional LSTM\":\n",
        "    save_model_and_tokenizer(bi_lstm_model, tokenizer, \"best_model\", \"tokenizer.pkl\")\n",
        "    files.download('best_model.pkl')\n",
        "elif best_model == \"Random Forest\":\n",
        "    save_model_and_tokenizer(rf_grid, tokenizer, \"best_model\", \"tokenizer.pkl\")\n",
        "    files.download('best_model.pkl')\n",
        "elif best_model == \"Linear Regression\":\n",
        "    save_model_and_tokenizer(lr_grid, tokenizer, \"best_model\", \"tokenizer.pkl\")\n",
        "    files.download('best_model.pkl')\n",
        "elif best_model == \"XGBoost\":\n",
        "    save_model_and_tokenizer(xgb_grid, tokenizer, \"best_model\", \"tokenizer.pkl\")\n",
        "    files.download('best_model.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xdiRO4lo1A-"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
